Ergodic theory is the study of dynamical systems from the point of view of measure theory, hence of probability. \\
One first measure comes from analytical mechanics. We consider a measure space $M$, and in this space we have an energetic hypersurface. Then we define the Liouville measure as
$$
	d\mu = \frac{d\sigma}{|\nabla H|}
$$
where $d\sigma$ is the measure of an infinitesimal portion of the hypersurface and $\nabla H$ is the gradient of the hamiltonian of the system. \\
We can derive the expression for the Liouville measure by considering the hypersurface with a bit of thickness in the direction of the gradient, forming in this way a volume $A$, and of course the system's dynamics is going to conserve the Lebesgue measure of $A$
$$
	Leb(A^t) = Leb(\phi^t(A)) = Leb(A)
$$
If we then move in the direction of the gradient by a quantity $h$, we increase the energy by a quantity
$$
	\Delta H = |\nabla H|h
$$
Then the conservation of the Lebesgue measure implies that
$$
	\sigma(B^t)h^t = \sigma(B)h
$$
so we are not only on the same energy surface, we are in the same energy shell. We can write this as
$$
	\frac{\sigma(B^t)\Delta H}{|\nabla H_f|} = \frac{\sigma(B)\Delta H}{|\nabla H_i|}
$$
and we can simplify the delta, so
$$
	\frac{\sigma(B^t)}{|\nabla H_f|} = \frac{\sigma(B)}{|\nabla H_i|}
$$
and we have thus obtained the expression for the Liouville measure. \\ \\ 
In ergodic theory we consider the space, along with the measure and the systems flux, $(M,\mu,\phi^t)$, or in discrete time $(M,\mu,T)$. \\
The first thing that we could ask ourselves is the probability that $\phi^t \in A$. So now we don't consider a single trajectory but all the possible trajectories, and want to find the probability that they are contained in a certain portion of space. This probability is equal to 
$$
	P(\phi^t \in A) = \mu(\phi^{-t}(A)) = \mu(\{x\in M \ | \ \phi^t(x) \in A\})
$$
A this point we can define the concept of a measure preserved by the dynamics
\begin{definition}
	A measure is preserved by the dynamics if 
	$$
		\mu(\phi^{-t}(A)) = \mu(A)
	$$
	where $A$ must be measurable, so it must belong the the $\sigma-$algebra of the space.
\end{definition}
From now on we restrict to measures that preserve the dynamics, which are also called invariant measures. \\ \\
An example of a measure preserving dynamical system is the doubling map. To see this, if we take the counter image of a set $A$, this is equal to the union of two sets $A_1$ and $A_2$, which are measurable. In this case it is important to consider the counter image of the set, because the image wouldn't preserve the set
$$
	\mu(TA) \neq \mu(A)
$$
When the two are equal, we have forward preservation. \\
An observable is any function of the phase space, $f:M \rightarrow R$, that represents any quantity of the system that can be observed and measured, thus giving us information about the system. An observable could the the temperature in a room, the moment of a particle or anything really.
\begin{definition}
	An observable $f:M \rightarrow R$ is said to be dynamics invariant (in ergodic theory) if
	$$
		f \circ \phi^t(x) = f(x)
	$$
\end{definition}
We notice that this is equivalent to the definition that we had before, but in the study of dynamical systems we asked for the relation to hold for every value of $x$, but we can't do this in ergodic theory, because not all the points in the space are seen by the measure. In ergodic theory we say that a relation holds if it holds almost everywhere, that is, if it doesn't hold only on subsets of the space that have zero measure. \\ \\
We also define the concept of an invariant set.
\begin{definition}
	A set $A$ is invariant if
	$$
		\phi^t(A) = A \ mod \ \mu
	$$
	We can also write it as
	$$
		\mu(\phi^{-t}A \Delta A) = 0
	$$
	where 
	$$
		A \Delta B = (A\cup B) - (A \cap B)
	$$
\end{definition}
We then define push-forward measures:
\begin{definition}
	We define a push-forward measure as
	$$
		\phi^t * \mu(A) = \mu(\phi^{-t}(A))
	$$
\end{definition}
The measure contains the counter image because we are considering the points at an initial time and this allows us to require that they will be in the set at forward times. We can say, in probability terms, that the probability of being in $A$ at time $t$ is the same as the probability of being in $A$ at previous times. \\ \\	
Now we can note that a measure $\mu$ is preserved by the dynamics if an only if
$$
	\phi^t * \mu = \mu
$$
Now, if $\phi^t * \mu \rightarrow \nu$, then $\nu$ is called an equilibrium measure.
\section{Birkhoff's ergodic theorem}
Given an observable $f:M\rightarrow M$ we define the Birkhoff (time) average as
$$
	f^*(x) = \lim_{t\rightarrow \infty} \frac{1}{T}\int_0^T f\circ \phi^t(x)dt
$$
The Birkhoff theorem states that:
\begin{prop}
	Given a measure preserving dynamical system $(M,\mu,T)$ with $\mu(M)=1$, if $f\in L^1(M,\mu)$, then 
	\begin{itemize}
		\item the limit $f^*$ exists almost everywhere
		\item 
			$$
				\int_M f^* d\mu = \int_M f d\mu
			$$
	\end{itemize}
\end{prop}
\begin{definition}
	A measure preserving dynamical system is ergodic if and only if for every $f\in L^1$ exists $c$ such that $f^*(x) = c$ for almost all values of $x$. 
\end{definition}
\begin{prop}
	The following statements are equivalent:
	\begin{itemize}
		\item $\forall f\in L^1$, $f^* = const$	
		\item $\forall f\in L^1$, $f^* = \int f d\mu$
		\item if $f \in L^1$ is invariant, then it is constant
		\item if $A \subseteq M$, which we take to be measurable, is invariant, the measure is $\mu(A) \in \{0,1\}$
	\end{itemize}
\end{prop}
\begin{proof}
	\begin{itemize}
		\item (1) implies (2) because, if $f^*$ is constant, by Birkhoff's theorem it's integral is equal to the integral of $f$. Since $f^*$ is constant, we can take is cout of the integral, and 
			$$
				\int d\mu = 1
			$$
			because $\mu$ is a probability measure. So
			$$
				f^* = \int f d\mu
			$$
		\item (2) implies (3) because, if we take $f$ invariant, so $f\circ T = f$, we can also say that $f\circ T^k = f$ for every $k$, which means that it is invariant at all times. This means that in calculating $f^*$ we are summing $f$ a number of times and then dividing by that number, so it remains $f$. But if $f^* = f$, by (2) we have that
			$$
				\int f d\mu = f
			$$
			which assures that $f$ is a constant.
		\item (3) implies (4) because, if we apply (3) to $f=1_A \in L^1$, knowing that $T^{-1}A=A \mod\mu$ it's true that $1_{f^{-1}_A}=1_A$ $\mu$-a.e.
			$1_{f^{-1}_A} = 1 \circ T$, so by (c) $1_A$ is constant $\mu$-a.e.
			So if $1_A = 0$, $A=\emptyset\mod\mu$ then $\mu(A)=0$, or if $1_A=1$, $A=M\mod\mu$ then $\mu(A)=1$
		\item (4) implies (1) because, if we claim that a function $f:M \rightarrow R$ is constant almost everywhere only if exists a constant $l$ such that $\mu(\{x\in M | f(x) \leq l\})\in (0,1)$, this set is increasing as we increase $l$. Now, if $l$ goes to $-\infty$ the measure goes to $0$, and if $l$ goes to $\infty$, the measure goes to $1$. The function can only jump in going from $0$ to $1$, but it can't do it all in one jump, so it must be constant except on the jumps.
	\end{itemize}	
\end{proof}
\begin{prop}
	$R_\al$ is ergodic if and only if $\al$ is not rational.	
\end{prop}
\begin{proof}
	Suppose that $\al$ was rational. Then, if $f(x) = \sin(2\pi q x)$ is invariant and not constant. If $\al$ was rational, we would have periodicity, thus the function would be constant. In fact for $R_\al(x) = \sin(2\pi q (x + p/q))$ we have
	$$
		R_\al(x) = \sin(2\pi q x + 2\pi p) = \sin(2\pi q x) = f(x)
	$$
	Now, suppose that $\al$ isn't rational. We want to prove that if $f\in L^1$ and for $f \circ R_\al = t$, then $f$ is constant. \\
	We know that we can expand functions with Fourier transform. If $f = f \circ R_\al$, this implies that $\hat{f} = \hat{f}\exp(2\pi k \al)$ $\forall k \neq 0$ , where the second piece is different from $1$. Then
	$$
		\hat{f}(k)(1-\exp(2\pi k \al)) = 0 \rita \hat{f}(k) = 0 
	$$
	$$
		f(x) = \hat{f}(0)\exp(2\pi i 0 x) = \hat{f}(0)
	$$
	which is constant.
\end{proof}
\begin{definition}
	A measure preserving dynamical system $(M,\mu,T)$ is called mixing if for all measurable $A,B \subseteq M$
	$$
		\mu(T^{-n}A\cap B) \rita \mu(A)\mu(B)
	$$
	$$
		\frac{\mu(T^{-n}A\cap B)}{\mu(B)} \rita \mu(A)
	$$
	as $n$ goes to infinity.
\end{definition}
This represents the portion of the counter-image of $A$ contained in $B$, renormalizedto $B$.
\begin{prop}
	If a system is ergodic, then give any $A\subseteq M$ with $\mu(A) > 0$, we have
	$$
		\frac{\# \{0 \ll k \ll n-1 | T^k(x)\in A\}}{n} \rita \mu(A)
	$$
	where this represents the frequency of visits in $A$.
\end{prop}
\begin{proof}
	We apply ergodicity fo $f = 1_A$	
	$$
		1_A(x) = \lim_{n\rita\infty} \frac{1}{n}\sum_{k=0}^{n-1}1_A \circ T^k(x) = \int_M 1_A d\mu
	$$
	where the integral of the indicator function is simply the measure.
\end{proof}
\begin{prop}
	Mixing implies ergodicity.
\end{prop}
\begin{proof}
	Mixing means that $\mu(T^{-n}A \cap A) \rita \mu(A)^2$. Suppose that $A$ is invariant. Then
	$$
		T^{-n}A = A \ mod \ \mu
	$$
	So we substitute this formula in the first one
	$$
		\mu(A \cap A) = \mu(A)
	$$
	so at this point we have the equality 
	$$
		\mu(A) = \mu(A)^2
	$$
	and the only numbers equal to their squares are $0$ and $1$, so the measure is either $0$ or $1$.
\end{proof}
\begin{prop}
	$(M,\mu,T)$ is mixing if and only if, $\forall f,g \in L^2(M,\mu)$
	$$
		\int (f\circ T^n)g d\mu \rita \int f d\mu \int g d\mu 
	$$
\end{prop}
We note that
$$
	\int f d\mu = \int (f\circ T^n) d\mu
$$
because the measure is preserved.
\begin{proof}
	We take $f = 1_A$ and $g = 1_B$. So we get
	$$
		\int (1_A \circ T^n)1_B d\mu \rita \int 1_A d\mu \int 1_B d\mu
	$$
	where $1_A \circ T^{-n} = 1_{T^{-n}(A)}$ and $1_{T{-n}A\cap B}$.
	So we get
	$$
		\mu(T^{-n}A\cap B) \rita \mu(A)\mu(B)
	$$
\end{proof}
\begin{prop}
	If I prove the previous proposition for $f,g\in S$, where $S$ is a dense subspace of $L^2$, then it works $\forall f,g \in L^2$.	
\end{prop}
Now we want to prove that the doubling map $T_2$ is mixing. We take $f = e_j$, where $e_j$ is the jth vector of the fourier basis, $e_j(x) = \exp(2\pi ij x)$, and we also take $g = \overline{e}_k$.
$$
	\int e_j d Leb = \int_0^1 \exp(2\pi i j x) dx = \left(\frac{\exp(2\pi i j x)}{2\pi i j}\right)_0^1 = 1-1 = 0
$$
if $j \neq 0$. If $j=0$ then 
$$
	\int e_j d Leb = \int_0^1 \exp(2\pi i j x) dx = \delta_{j0}
$$
Also
$$
	\int \overline{e}_ke_j d Leb = \int e_{k-j} dx = \delta_{jk}
$$
So we combine these to get
$$
	\int (f\circ T^n)g d Leb = \int (e_j \circ T^n)\overline{e}_k d Leb
$$
where 
$$
	e_j \circ T^n(x) = \exp(2\pi i j 2^n x) = \exp(2\pi i (2^n j) x) = e_{2^n j}(x)
$$
So finally
$$
	\int e_{2^n j}\overline{e}_k d Leb = \delta_{2^nj,k} \rita 0 = \int e_j d Leb \int \overline{e}_k d Leb
$$
So it works for $f = e_j$ and $g = \overline{e}_k$, and this means that it also works for finite linear combinations of basis vectors. \\ \\
We can prove the same thing for the cat map. By the same argument, suffices to show that the previous relation holds for $f = e_k = e_{(k_1,k_2)}$ and $g = \overline{e}_j$. \\
We observe that 
$$
	e_k \circ T_A^n(x) = \exp(2\pi i \lang k, T_A^n x \rang) = \exp(2\pi i \lang k, A x \rang) = \exp(2\pi i \lang (A^t)^n k, x \rang) = e_{A^nk}
$$ 
Now, if we do the integral it's equivalent to the integral
$$
	\int (e_k \circ T_A^n)\overline{e}_jd Leb = \int e_{A^n k} \overline{e}_j d Leb = \delta_{A^nk,j}
$$














